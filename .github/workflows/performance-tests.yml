name: Performance Tests

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to test'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

env:
  NODE_VERSION: '22'

jobs:
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: '8'

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Install Artillery
        run: pnpm add -g artillery

      - name: Run k6 Load Tests
        if: ${{ secrets.PERF_TEST_EMAIL != '' }}
        run: |
          cd tests/performance
          k6 run --out json=results-k6.json k6-load-test.js
        env:
          BASE_URL: ${{ github.event.inputs.environment == 'production' && 'https://api.luneo.app' || 'https://staging-api.luneo.app' }}
          TEST_EMAIL: ${{ secrets.PERF_TEST_EMAIL }}
          TEST_PASSWORD: ${{ secrets.PERF_TEST_PASSWORD }}

      - name: Run Artillery Stress Tests
        run: |
          cd tests/performance
          artillery run --output results-artillery.json artillery-config.yml
        env:
          BASE_URL: ${{ github.event.inputs.environment == 'production' && 'https://api.luneo.app' || 'https://staging-api.luneo.app' }}

      - name: Upload Test Results
        uses: actions/upload-artifact@v6
        if: always()
        with:
          name: performance-test-results
          path: |
            tests/performance/results-*.json
          retention-days: 30

      - name: Generate Performance Report
        run: |
          echo "## Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### k6 Results" >> $GITHUB_STEP_SUMMARY
          if [ -f tests/performance/results-k6.json ]; then
            cat tests/performance/results-k6.json | jq -r '.metrics | to_entries[] | "\(.key): \(.value.values)"' >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artillery Results" >> $GITHUB_STEP_SUMMARY
          # Report generation is non-critical - || true so step does not fail if report fails
          if [ -f tests/performance/results-artillery.json ]; then
            artillery report tests/performance/results-artillery.json >> $GITHUB_STEP_SUMMARY || true
          fi

      - name: Check Performance Thresholds
        run: |
          # Parse k6 results and check thresholds
          if [ -f tests/performance/results-k6.json ]; then
            p95=$(cat tests/performance/results-k6.json | jq -r '.metrics.http_req_duration.values.p95')
            error_rate=$(cat tests/performance/results-k6.json | jq -r '.metrics.http_req_failed.values.rate')
            
            echo "p95 Latency: ${p95}ms"
            echo "Error Rate: ${error_rate}"
            
            if (( $(echo "$p95 > 1000" | bc -l) )); then
              echo "❌ p95 latency exceeds threshold (1000ms)"
              exit 1
            fi
            
            if (( $(echo "$error_rate > 0.01" | bc -l) )); then
              echo "❌ Error rate exceeds threshold (1%)"
              exit 1
            fi
            
            echo "✅ Performance thresholds met"
          fi
