# ğŸ¯ PLAN D'ACTION - PHASE 2: MONITORING & QUALITÃ‰

## ğŸ“‹ OBJECTIFS

**DurÃ©e estimÃ©e**: 5-7 jours  
**PrioritÃ©**: ğŸŸ¡ HAUTE

---

## âœ… TÃ‚CHE 2.1: Monitoring & Observability

### Objectif
VisibilitÃ© complÃ¨te sur les performances, coÃ»ts et erreurs des agents IA

### Fichiers Ã  crÃ©er
- `apps/backend/src/modules/agents/services/agent-metrics.service.ts`
- `apps/backend/src/modules/agents/services/agent-tracing.service.ts`

### Ã‰tapes
1. âœ… CrÃ©er mÃ©triques Prometheus
2. âœ… Instrumenter tous les appels LLM
3. âœ… Ajouter traces distribuÃ©es
4. âœ… Logging structurÃ© avec contexte

### MÃ©triques Ã  implÃ©menter
- `agent_request_duration_seconds` (Histogram)
- `agent_tokens_total` (Counter)
- `agent_cost_total` (Counter)
- `agent_errors_total` (Counter)
- `agent_retries_total` (Counter)
- `agent_circuit_breaker_state` (Gauge)

---

## âœ… TÃ‚CHE 2.2: AmÃ©lioration Intent Detection

### Objectif
DÃ©tection d'intention plus prÃ©cise avec ML au lieu de mots-clÃ©s

### Fichiers Ã  modifier
- `apps/backend/src/modules/agents/luna/luna.service.ts`
- `apps/backend/src/modules/agents/aria/aria.service.ts`
- `apps/backend/src/modules/agents/nova/nova.service.ts`

### Ã‰tapes
1. âœ… Remplacer dÃ©tection par mots-clÃ©s par LLM classification
2. âœ… Utiliser Claude Haiku (rapide + pas cher)
3. âœ… Calculer confidence score rÃ©el
4. âœ… Cache les rÃ©sultats de classification

---

## âœ… TÃ‚CHE 2.3: Gestion Contexte Long

### Objectif
Optimiser les tokens envoyÃ©s au LLM en compressant l'historique

### Fichiers Ã  crÃ©er/modifier
- `apps/backend/src/modules/agents/services/context-manager.service.ts` (NOUVEAU)
- `apps/backend/src/modules/agents/services/conversation.service.ts`

### Ã‰tapes
1. âœ… CrÃ©er service de summarization
2. âœ… Compresser historique ancien
3. âœ… Garder seulement contexte rÃ©cent
4. âœ… Optimiser prompts systÃ¨me

---

## ğŸ“Š CHECKLIST

### Phase 2.1 - Monitoring
- [ ] MÃ©triques Prometheus crÃ©Ã©es
- [ ] Instrumentation complÃ¨te
- [ ] Traces distribuÃ©es
- [ ] Logging structurÃ©

### Phase 2.2 - Intent Detection
- [ ] Classification LLM implÃ©mentÃ©e
- [ ] Confidence score calculÃ©
- [ ] Cache activÃ©
- [ ] Tests de prÃ©cision

### Phase 2.3 - Contexte Long
- [ ] Service summarization crÃ©Ã©
- [ ] Compression historique
- [ ] Optimisation prompts
- [ ] Tests de rÃ©duction tokens

---

## ğŸ§ª TESTS Ã€ EFFECTUER

### Tests Unitaires
- MÃ©triques enregistrÃ©es correctement
- Intent detection prÃ©cision > 90%
- Summarization rÃ©duit tokens de 30%+

### Tests d'IntÃ©gration
- MÃ©triques visibles dans Prometheus
- Intent detection fonctionne en production
- Contexte long optimisÃ©

---

## ğŸ“ˆ MÃ‰TRIQUES DE SUCCÃˆS

- âœ… MÃ©triques Prometheus disponibles
- âœ… Intent detection > 90% prÃ©cision
- âœ… RÃ©duction 30% tokens envoyÃ©s
- âœ… Logging structurÃ© complet

---

**DÃ©marrage immÃ©diat de l'implÃ©mentation**
